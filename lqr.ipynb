{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/flow/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1600px;height:750px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([[1.], [1.]])  # 2x1 vector \n",
    "\n",
    "A = tf.constant(np.array([[-0.5, 0], [0, -0.6]]), dtype=tf.float32, name='A')  # system dynamics\n",
    "B = tf.constant(np.array([[1.], [1.]]), dtype=tf.float32, name='B')\n",
    "\n",
    "Q = tf.constant([[1.,0.], [0.,1.]], name='Q')  # weighting\n",
    "R = tf.constant(1., name='R')\n",
    "\n",
    "x = tf.constant(x0, dtype=tf.float32, name=\"state\")\n",
    "\n",
    "T = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "####### Defining network #######\n",
    "# input: state x\n",
    "# output: control u\n",
    "\n",
    "input_layer = tf.placeholder(tf.float32, (None,2), name='in_layer')\n",
    "# fc1 = tf.layers.dense(inputs=input_layer, units=2,) #activation=tf.nn.sigmoid)\n",
    "# fc2 = tf.layers.dense(inputs=fc1, units=2, activation=tf.nn.sigmoid)\n",
    "u = tf.layers.dense(inputs=input_layer, units=1, name='u_out_layer', reuse=tf.AUTO_REUSE)\n",
    "\n",
    "### LOSS FUNCTION ### \n",
    "loss = tf.add(tf.matmul(tf.matmul(tf.transpose(x), Q), x), \n",
    "              tf.matmul(tf.transpose(u), tf.multiply(R, u)), name='loss')\n",
    "\n",
    "# xs = tf.identity(x, name='xs')\n",
    "# us = tf.constant(0, name='us')\n",
    "xs = x\n",
    "us = u\n",
    "\n",
    "# cond = lambda i, x, l, xs, us: i < T\n",
    "\n",
    "# def body(i, x, l, xs, us):\n",
    "#     next_i = i+1\n",
    "#     next_x = tf.add(tf.matmul(A, x), tf.multiply(u,B))\n",
    "#     next_l = tf.add(l,\n",
    "#                     tf.add(tf.matmul(tf.matmul(tf.transpose(x), Q), x),\n",
    "#                            tf.matmul(tf.transpose(u), tf.multiply(R, u))))\n",
    "#     next_xs = tf.concat(xs, next_x)\n",
    "#     next_us = tf.concat(us, u)\n",
    "#     return (next_i, next_x, next_l, next_xs, next_us)\n",
    "\n",
    "# i, xloss_f, traj_f = tf.while_loop(cond, body, \n",
    "#                                    loop_vars=[tf.constant(0), x, loss, xs, us],\n",
    "#                                    shape_invariants=[tf.TensorShape([1,]), tf.TensorShape([2, 1]), \n",
    "#                                                      tf.TensorShape([1,]) , tf.TensorShape([2, None]), \n",
    "#                                                      tf.TensorShape([1, None])])\n",
    "# train = tf.train.GradientDescentOptimizer(0.01).minimize(xloss_f.loss)\n",
    "\n",
    "for i in range(T):\n",
    "    # LQR loss \n",
    "#     x_term = tf.matmul(tf.matmul(tf.transpose(x), Q), x, name='x_term')\n",
    "#     u_term = tf.matmul(tf.transpose(u), tf.multiply(R, u), name='u_term')\n",
    "#     loss = tf.add(loss, tf.add(x_term, u_term), name='loss')  # accumulate loss\n",
    "    \n",
    "    # Dynamics: advancing the system dynamics\n",
    "    Ax = tf.matmul(A, x, name='Ax'+str(i))\n",
    "    Bu = tf.multiply(u, B, name='Bu'+str(i))  # tf.multiply because u is a scalar\n",
    "    x = tf.add(Ax, Bu, name='state'+str(i))  # next state vector\n",
    "\n",
    "    loss = tf.add(loss, tf.add(tf.matmul(tf.matmul(tf.transpose(x), Q), x), tf.matmul(tf.transpose(u), tf.multiply(R, u))), name='loss'+str(i))  # accumulate loss    \n",
    "    \n",
    "    u = tf.layers.dense(inputs=tf.transpose(x), units=1, name='u_out_layer', reuse=True)\n",
    "    \n",
    "    xs = tf.concat([xs, x], 1)\n",
    "    us = tf.concat([us, u], 1)\n",
    "    \n",
    "opt = tf.train.GradientDescentOptimizer(0.0001)\n",
    "train = opt.minimize(loss)\n",
    "grads_and_vars = opt.compute_gradients(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training iteration 0\n",
      "xs\n",
      "[[ 1.         -0.4970896   0.37587583 -0.32742983  0.29586723 -0.26849094\n",
      "   0.24479899 -0.22247541  0.2029894  -0.1844219   0.16834217]\n",
      " [ 1.         -0.5970896   0.48558483 -0.43084282  0.39065802 -0.35495216\n",
      "   0.3235248  -0.29419082  0.2682662  -0.24388692  0.22246337]]\n",
      "\n",
      "us\n",
      "[[ 0.00291041  0.12733105 -0.13949192  0.13215232 -0.12055733  0.11055351\n",
      "  -0.10007592  0.0917517  -0.08292719  0.07613122 -0.06870268]]\n",
      "\n",
      "loss\n",
      "[[4.407901]]\n",
      "\n",
      "gradients\n",
      "[[-15.519047]\n",
      " [-18.11099 ]] - u_out_layer/kernel:0\n",
      "gradients\n",
      "[-2.9853582] - u_out_layer/bias:0\n",
      "----------------------\n",
      "training iteration 50\n",
      "xs\n",
      "[[ 1.         -0.3820171   0.281263   -0.22121912  0.20247486 -0.161154\n",
      "   0.1517719  -0.11763153  0.1143171  -0.0853859   0.0865545 ]\n",
      " [ 1.         -0.48201713  0.37946475 -0.3082665   0.2768252  -0.2260117\n",
      "   0.20680192 -0.16582674  0.15499738 -0.12122578  0.11659703]]\n",
      "\n",
      "us\n",
      "[[ 0.11798289  0.09025445 -0.08058763  0.09186529 -0.05991656  0.07119491\n",
      "  -0.04174558  0.05550133 -0.02822735  0.04386155 -0.01820564]]\n",
      "\n",
      "loss\n",
      "[[3.1944516]]\n",
      "\n",
      "gradients\n",
      "[[-6.4995947]\n",
      " [-7.62613  ]] - u_out_layer/kernel:0\n",
      "gradients\n",
      "[-0.9512671] - u_out_layer/bias:0\n",
      "----------------------\n",
      "training iteration 100\n",
      "xs\n",
      "[[ 1.         -0.32340956  0.23977205 -0.17898445  0.16670741 -0.12243296\n",
      "   0.1197791  -0.08315751  0.0868758  -0.05558936  0.06377743]\n",
      " [ 1.         -0.42340958  0.33211303 -0.25836626  0.23223495 -0.17842023\n",
      "   0.16561475 -0.12263681  0.11887914 -0.08347895  0.08607013]]\n",
      "\n",
      "us\n",
      "[[ 0.17659044  0.07806727 -0.05909843  0.07721519 -0.03907925  0.05856262\n",
      "  -0.02326796  0.04529705 -0.01215146  0.03598275 -0.0043473 ]]\n",
      "\n",
      "loss\n",
      "[[2.8728504]]\n",
      "\n",
      "gradients\n",
      "[[-4.086339 ]\n",
      " [-4.8452506]] - u_out_layer/kernel:0\n",
      "gradients\n",
      "[-0.16280243] - u_out_layer/bias:0\n",
      "----------------------\n",
      "training iteration 150\n",
      "xs\n",
      "[[ 1.         -0.2857583   0.21399795 -0.15616158  0.14555897 -0.10264068\n",
      "   0.10170104 -0.06654514  0.07198244 -0.04207602  0.05183548]\n",
      " [ 1.         -0.3857583   0.3025738  -0.23070689  0.20590232 -0.1534026\n",
      "   0.14242226 -0.10114798  0.09939866 -0.06572399  0.07023187]]\n",
      "\n",
      "us\n",
      "[[ 0.21424171  0.0711188  -0.0491626   0.06747818 -0.0298612   0.05038069\n",
      "  -0.01569462  0.03870987 -0.0060848   0.03079747  0.00042998]]\n",
      "\n",
      "loss\n",
      "[[2.7271204]]\n",
      "\n",
      "gradients\n",
      "[[-2.9178631]\n",
      " [-3.508706 ]] - u_out_layer/kernel:0\n",
      "gradients\n",
      "[0.22939056] - u_out_layer/bias:0\n",
      "----------------------\n",
      "training iteration 200\n",
      "xs\n",
      "[[ 1.         -0.25923946  0.19558346 -0.14240557  0.13064586 -0.09128439\n",
      "   0.08917116 -0.05756478  0.06175257 -0.03526955  0.04362334]\n",
      " [ 1.         -0.3592395   0.28150743 -0.2135183   0.18755406 -0.13849391\n",
      "   0.1266253  -0.08895439  0.08634281 -0.05619896  0.05970794]]\n",
      "\n",
      "us\n",
      "[[ 0.24076054  0.06596374 -0.04461384  0.05944307 -0.02596146  0.04352896\n",
      "  -0.01297921  0.03297017 -0.00439327  0.02598857  0.00128378]]\n",
      "\n",
      "loss\n",
      "[[2.6460614]]\n",
      "\n",
      "gradients\n",
      "[[-2.2190962]\n",
      " [-2.7136242]] - u_out_layer/kernel:0\n",
      "gradients\n",
      "[0.42050093] - u_out_layer/bias:0\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "# show_graph(tf.get_default_graph().as_graph_def())\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(250):\n",
    "#         sess.run(train)\n",
    "        sess.run(train, feed_dict={input_layer : x0.T})\n",
    "        if i % 50 == 0:\n",
    "#             results = sess.run([xs, us, loss, grads_and_vars], feed_dict={input_layer : x0.T})\n",
    "            results = sess.run([xs, us, loss], feed_dict={input_layer : x0.T})\n",
    "            labels  = \"xs us loss\".split(' ')\n",
    "            print('training iteration', i)\n",
    "            for label,result in zip(*(labels,results)) :\n",
    "                print(label)\n",
    "                print(result)\n",
    "                print('')\n",
    "            for g, v in grads_and_vars:\n",
    "                print('gradients')\n",
    "                print(str(sess.run(g, feed_dict={input_layer : x0.T})) + \" - \" + v.name)\n",
    "            print('----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## compute optimal loss with true LQR ricatti equation formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import controlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if type(A) != np.ndarray:  # if tensors not already evaluated\n",
    "    with tf.Session() as sess:\n",
    "        A, B, Q, R = sess.run([A, B, Q, R])\n",
    "\n",
    "K, P, eig = controlpy.synthesis.controller_lqr_discrete_time(A, B, Q, R)\n",
    "x = x0\n",
    "u = (-K@x)\n",
    "xs, us = np.array(x), np.array(u)\n",
    "loss = 0\n",
    "for i in range(T):\n",
    "    loss += x.T@Q@x + u.T*R*u\n",
    "    x = A@x + B@u\n",
    "    u = (-K@x)\n",
    "    xs = np.hstack([xs, x])\n",
    "    us = np.hstack([us, u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 11)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.80738770e-01, -6.70907865e-02,  1.27556619e-02,\n",
       "        -2.91909818e-03,  9.10254339e-04, -3.82533515e-04,\n",
       "         1.90269282e-04, -1.01185839e-04,  5.50383161e-05,\n",
       "        -3.01523452e-05,  1.65556325e-05]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
