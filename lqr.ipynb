{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/flow/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/envs/flow/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from ray.experimental.tfutils import TensorFlowVariables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1600px;height:750px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1.001, 0], [0, 0.5]])\n",
    "B = np.array([[1.], [1.]])\n",
    "\n",
    "# for controllability\n",
    "cont = np.hstack([B, A@B, A@A@B])\n",
    "assert np.linalg.matrix_rank(cont)==cont.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([[1.], [1.]])  # 2x1 vector \n",
    "\n",
    "A = tf.constant(np.array([[1.001, 0], [0, -0.6]]), dtype=tf.float32, name='A')  # system dynamics\n",
    "B = tf.constant(np.array([[1.], [1.]]), dtype=tf.float32, name='B')\n",
    "\n",
    "Q = tf.constant([[1.,0.], [0.,1.]], name='Q')  # weighting\n",
    "R = tf.constant(1., name='R')\n",
    "\n",
    "x = tf.constant(x0, dtype=tf.float32, name=\"state\")\n",
    "\n",
    "T = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "####### Defining network #######\n",
    "# input: state x\n",
    "# output: control u\n",
    "\n",
    "input_layer = tf.placeholder(tf.float32, (None,2), name='in_layer')\n",
    "# fc1 = tf.layers.dense(inputs=input_layer, units=1, name='fc1', reuse=tf.AUTO_REUSE)\n",
    "# u = tf.layers.dense(inputs=fc1, units=1, name='fc_out', reuse=tf.AUTO_REUSE)\n",
    "u = tf.layers.dense(inputs=input_layer, units=1, name='u_out_layer', reuse=tf.AUTO_REUSE)\n",
    "\n",
    "### LOSS FUNCTION ### \n",
    "loss = tf.add(tf.matmul(tf.matmul(tf.transpose(x), Q), x), \n",
    "              tf.matmul(tf.transpose(u), tf.multiply(R, u)), name='loss')\n",
    "\n",
    "# xs = tf.identity(x, name='xs')\n",
    "# us = tf.constant(0, name='us')\n",
    "xs = x\n",
    "us = u\n",
    "\n",
    "# cond = lambda i, x, l, xs, us: i < T\n",
    "\n",
    "# def body(i, x, l, xs, us):\n",
    "#     next_i = i+1\n",
    "#     next_x = tf.add(tf.matmul(A, x), tf.multiply(u,B))\n",
    "#     next_l = tf.add(l,\n",
    "#                     tf.add(tf.matmul(tf.matmul(tf.transpose(x), Q), x),\n",
    "#                            tf.matmul(tf.transpose(u), tf.multiply(R, u))))\n",
    "#     next_xs = tf.concat(xs, next_x)\n",
    "#     next_us = tf.concat(us, u)\n",
    "#     return (next_i, next_x, next_l, next_xs, next_us)\n",
    "\n",
    "# i, xloss_f, traj_f = tf.while_loop(cond, body, \n",
    "#                                    loop_vars=[tf.constant(0), x, loss, xs, us],\n",
    "#                                    shape_invariants=[tf.TensorShape([1,]), tf.TensorShape([2, 1]), \n",
    "#                                                      tf.TensorShape([1,]) , tf.TensorShape([2, None]), \n",
    "#                                                      tf.TensorShape([1, None])])\n",
    "# train = tf.train.GradientDescentOptimizer(0.01).minimize(xloss_f.loss)\n",
    "\n",
    "for i in range(T):\n",
    "    # LQR loss \n",
    "#     x_term = tf.matmul(tf.matmul(tf.transpose(x), Q), x, name='x_term')\n",
    "#     u_term = tf.matmul(tf.transpose(u), tf.multiply(R, u), name='u_term')\n",
    "#     loss = tf.add(loss, tf.add(x_term, u_term), name='loss')  # accumulate loss\n",
    "    \n",
    "    # Dynamics: advancing the system dynamics\n",
    "    Ax = tf.matmul(A, x, name='Ax'+str(i))\n",
    "    Bu = tf.multiply(u, B, name='Bu'+str(i))  # tf.multiply because u is a scalar\n",
    "    x = tf.add(Ax, Bu, name='state'+str(i))  # next state vector\n",
    "\n",
    "    loss = tf.add(loss, tf.add(tf.matmul(tf.matmul(tf.transpose(x), Q), x), tf.matmul(tf.transpose(u), tf.multiply(R, u))), name='loss'+str(i))  # accumulate loss    \n",
    "    \n",
    "    u = tf.layers.dense(inputs=tf.transpose(x), units=1, name='u_out_layer', reuse=True)\n",
    "    \n",
    "#     fc1 = tf.layers.dense(inputs=tf.transpose(x), units=1, name='fc1', reuse=True)\n",
    "#     u = tf.layers.dense(inputs=fc1, units=1, name='fc_out', reuse=True)\n",
    "    \n",
    "    xs = tf.concat([xs, x], 1)\n",
    "    us = tf.concat([us, u], 1)\n",
    "    \n",
    "opt = tf.train.GradientDescentOptimizer(0.0001)\n",
    "train = opt.minimize(loss)\n",
    "grads_and_vars = opt.compute_gradients(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "variables = TensorFlowVariables(loss, sess)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training iteration 0\n",
      "xs\n",
      "[[ 1.0000000e+00  7.9210770e-01  8.4022564e-01  6.9398147e-01\n",
      "   6.8784302e-01  5.7313091e-01  5.3444093e-01  4.3443611e-01\n",
      "   3.7497041e-01  2.8017014e-01  2.0620668e-01]\n",
      " [ 1.0000000e+00 -8.0889237e-01  5.3266126e-01 -4.6668118e-01\n",
      "   2.7317628e-01 -2.7930582e-01  1.2832037e-01 -1.7753151e-01\n",
      "   4.6618737e-02 -1.2314651e-01 -3.5573542e-04]]\n",
      "\n",
      "us\n",
      "[[-0.20889235  0.04732581 -0.1470844  -0.00683246 -0.11540003 -0.03926314\n",
      "  -0.1005393  -0.05990017 -0.09517527 -0.07424364 -0.09527966]]\n",
      "\n",
      "loss\n",
      "[[6.880715]]\n",
      "\n",
      "gradients\n",
      "[[33.50622  ]\n",
      " [-3.7056055]] - u_out_layer/kernel:0\n",
      "gradients\n",
      "[44.501514] - u_out_layer/bias:0\n",
      "----------------------\n",
      "training iteration 100\n",
      "xs\n",
      "[[ 1.          0.76100516  0.6996459   0.51779604  0.42277429  0.27034062\n",
      "   0.16078025  0.02430081 -0.09059306 -0.217677   -0.33349657]\n",
      " [ 1.         -0.8399949   0.44187665 -0.44767556  0.17306575 -0.25669593\n",
      "   0.04418683 -0.16315232 -0.01702678 -0.11677727 -0.04553551]]\n",
      "\n",
      "us\n",
      "[[-0.23999491 -0.06212031 -0.18254957 -0.0955396  -0.15285645 -0.10983074\n",
      "  -0.13664022 -0.11491818 -0.12699334 -0.11560187 -0.12057276]]\n",
      "\n",
      "loss\n",
      "[[5.2817974]]\n",
      "\n",
      "gradients\n",
      "[[ 3.6102834]\n",
      " [-4.2143774]] - u_out_layer/kernel:0\n",
      "gradients\n",
      "[-1.4632452] - u_out_layer/bias:0\n",
      "----------------------\n",
      "training iteration 200\n",
      "xs\n",
      "[[ 1.0000000e+00  7.7505171e-01  6.6865379e-01  4.9644744e-01\n",
      "   3.7959719e-01  2.3748574e-01  1.2281031e-01  2.3507327e-04\n",
      "  -1.0740019e-01 -2.1565875e-01 -3.1471357e-01]\n",
      " [ 1.0000000e+00 -8.2594836e-01  3.8839599e-01 -4.0591264e-01\n",
      "   1.2620085e-01 -2.1821159e-01  1.6014047e-02 -1.3230649e-01\n",
      "  -2.8251603e-02 -9.1200188e-02 -4.4119027e-02]]\n",
      "\n",
      "us\n",
      "[[-0.2259483  -0.10717303 -0.17287505 -0.11734673 -0.14249107 -0.11491292\n",
      "  -0.12269805 -0.1076355  -0.10815115 -0.09883914 -0.09645852]]\n",
      "\n",
      "loss\n",
      "[[4.995963]]\n",
      "\n",
      "gradients\n",
      "[[ 3.6628976]\n",
      " [-3.122295 ]] - u_out_layer/kernel:0\n",
      "gradients\n",
      "[-1.4276664] - u_out_layer/bias:0\n",
      "----------------------\n",
      "training iteration 300\n",
      "xs\n",
      "[[ 1.0000000e+00  7.8090572e-01  6.3620317e-01  4.6860021e-01\n",
      "   3.3754382e-01  2.0357510e-01  8.9917593e-02 -1.9682691e-02\n",
      "  -1.1639037e-01 -2.0710742e-01 -2.8867546e-01]\n",
      " [ 1.0000000e+00 -8.2009435e-01  3.4657311e-01 -3.7618306e-01\n",
      "   9.4184831e-02 -1.9081718e-01  6.2921643e-04 -1.1006773e-01\n",
      "  -3.0647352e-02 -7.2212256e-02 -3.8033567e-02]]\n",
      "\n",
      "us\n",
      "[[-0.22009432 -0.14548352 -0.16823919 -0.13152501 -0.13430628 -0.11386109\n",
      "  -0.1096902  -0.09668799 -0.09060067 -0.08136092 -0.07522888]]\n",
      "\n",
      "loss\n",
      "[[4.7678213]]\n",
      "\n",
      "gradients\n",
      "[[ 3.5137064]\n",
      " [-2.574056 ]] - u_out_layer/kernel:0\n",
      "gradients\n",
      "[-1.2859735] - u_out_layer/bias:0\n",
      "----------------------\n",
      "training iteration 400\n",
      "xs\n",
      "[[ 1.          0.78297335  0.60386384  0.43914855  0.2986028   0.17233326\n",
      "   0.06286116 -0.03440811 -0.1193814  -0.19448638 -0.26033536]\n",
      " [ 1.         -0.8180267   0.31092352 -0.3518733   0.07013907 -0.1686516\n",
      "  -0.00845348 -0.09226005 -0.02958285 -0.05723589 -0.03131296]]\n",
      "\n",
      "us\n",
      "[[-0.21802668 -0.17989254 -0.16531919 -0.14098492 -0.12656815 -0.10964444\n",
      "  -0.09733213 -0.08493888 -0.0749856  -0.06565449 -0.05779578]]\n",
      "\n",
      "loss\n",
      "[[4.5804353]]\n",
      "\n",
      "gradients\n",
      "[[ 3.26399  ]\n",
      " [-2.2419205]] - u_out_layer/kernel:0\n",
      "gradients\n",
      "[-1.1199293] - u_out_layer/bias:0\n",
      "----------------------\n",
      "training iteration 500\n",
      "xs\n",
      "[[ 1.          0.7833542   0.5728126   0.4104941   0.26385784  0.14516115\n",
      "   0.04154995 -0.04429763 -0.1180275  -0.17979982 -0.23244554]\n",
      " [ 1.         -0.81764585  0.27926254 -0.33044893  0.05122258 -0.14969411\n",
      "  -0.01393989 -0.07752519 -0.02717046 -0.04535202 -0.02525468]]\n",
      "\n",
      "us\n",
      "[[-0.21764584 -0.21132497 -0.16289139 -0.14704679 -0.11896056 -0.10375637\n",
      "  -0.08588913 -0.07368557 -0.06165429 -0.05246589 -0.04410936]]\n",
      "\n",
      "loss\n",
      "[[4.427164]]\n",
      "\n",
      "gradients\n",
      "[[ 2.9736834]\n",
      " [-2.005608 ]] - u_out_layer/kernel:0\n",
      "gradients\n",
      "[-0.9618152] - u_out_layer/bias:0\n",
      "----------------------\n",
      "training iteration 600\n",
      "xs\n",
      "[[ 1.          0.7830867   0.5437453   0.3837512   0.23360166  0.12227998\n",
      "   0.02530865 -0.05024607 -0.11380092 -0.16450743 -0.20646235]\n",
      " [ 1.         -0.81791335  0.2506234  -0.3109119   0.03601383 -0.13316359\n",
      "  -0.01719546 -0.06526276 -0.02434695 -0.03598453 -0.02019968]]\n",
      "\n",
      "us\n",
      "[[-0.21791333 -0.24012461 -0.16053784 -0.15053332 -0.11155529 -0.09709361\n",
      "  -0.07558003 -0.06350461 -0.05059271 -0.0417904  -0.03364684]]\n",
      "\n",
      "loss\n",
      "[[4.3028045]]\n",
      "\n",
      "gradients\n",
      "[[ 2.6787405]\n",
      " [-1.8156565]] - u_out_layer/kernel:0\n",
      "gradients\n",
      "[-0.8233218] - u_out_layer/bias:0\n",
      "----------------------\n",
      "training iteration 700\n",
      "xs\n",
      "[[ 1.          0.7826664   0.51697886  0.35933393  0.20764092  0.10336097\n",
      "   0.01324936 -0.05321926 -0.10785902 -0.14953978 -0.18300894]\n",
      " [ 1.         -0.8183337   0.22452998 -0.29287994  0.02367559 -0.11869295\n",
      "  -0.0189992  -0.05508235 -0.02153712 -0.02865063 -0.01612922]]\n",
      "\n",
      "us\n",
      "[[-0.21833366 -0.26647025 -0.15816194 -0.15205237 -0.1044876  -0.09021498\n",
      "  -0.06648187 -0.05458653 -0.04157291 -0.0333196  -0.02575904]]\n",
      "\n",
      "loss\n",
      "[[4.2024746]]\n",
      "\n",
      "gradients\n",
      "[[ 2.3986742]\n",
      " [-1.6511269]] - u_out_layer/kernel:0\n",
      "gradients\n",
      "[-0.7065548] - u_out_layer/bias:0\n",
      "----------------------\n",
      "training iteration 800\n",
      "xs\n",
      "[[ 1.          0.7823075   0.49258214  0.33729273  0.1855483   0.08787471\n",
      "   0.00450089 -0.05405486 -0.10102981 -0.1354168  -0.16221645]\n",
      " [ 1.         -0.81869256  0.20070782 -0.2762067   0.0136423  -0.10604454\n",
      "  -0.01983497 -0.04665926 -0.01892534 -0.02293075 -0.01290578]]\n",
      "\n",
      "us\n",
      "[[-0.21869251 -0.29050773 -0.155782   -0.15208173 -0.09785916 -0.0834617\n",
      "  -0.05856025 -0.0469209  -0.03428596 -0.02666423 -0.01984403]]\n",
      "\n",
      "loss\n",
      "[[4.121748]]\n",
      "\n",
      "gradients\n",
      "[[ 2.1423802]\n",
      " [-1.5031409]] - u_out_layer/kernel:0\n",
      "gradients\n",
      "[-0.60965043] - u_out_layer/bias:0\n",
      "----------------------\n",
      "training iteration 900\n",
      "xs\n",
      "[[ 1.          0.78208303  0.47047973  0.31750578  0.16682144  0.07526584\n",
      "  -0.00169094 -0.0534105  -0.09386733 -0.12238212 -0.1439589 ]\n",
      " [ 1.         -0.81891704  0.1789648  -0.2608233   0.00549214 -0.09501771\n",
      "  -0.02002142 -0.03970502 -0.01658041 -0.01847267 -0.01037079]]\n",
      "\n",
      "us\n",
      "[[-0.218917   -0.31238544 -0.15344444 -0.15100186 -0.09172243 -0.07703204\n",
      "  -0.05171787 -0.04040342 -0.02842092 -0.02145439 -0.01540779]]\n",
      "\n",
      "loss\n",
      "[[4.056823]]\n",
      "\n",
      "gradients\n",
      "[[ 1.912556 ]\n",
      " [-1.3678969]] - u_out_layer/kernel:0\n",
      "gradients\n",
      "[-0.5295273] - u_out_layer/bias:0\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     for i in range(1000):\n",
    "# #         sess.run(train)\n",
    "#         sess.run(train, feed_dict={input_layer : x0.T})\n",
    "#         if i % 100 == 0:\n",
    "# #             results = sess.run([xs, us, loss, grads_and_vars], feed_dict={input_layer : x0.T})\n",
    "#             results = sess.run([xs, us, loss], feed_dict={input_layer : x0.T})\n",
    "#             labels  = \"xs us loss\".split(' ')\n",
    "#             print('training iteration', i)\n",
    "#             for label,result in zip(*(labels,results)) :\n",
    "#                 print(label)\n",
    "#                 print(result)\n",
    "#                 print('')\n",
    "#             for g, v in grads_and_vars:\n",
    "#                 print('gradients')\n",
    "#                 print(str(sess.run(g, feed_dict={input_layer : x0.T})) + \" - \" + v.name)\n",
    "#             print('----------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## compute optimal loss with true LQR ricatti equation formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import controlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    A_np, B_np, Q_np, R_np = sess.run([A, B, Q, R])\n",
    "\n",
    "K, P, eig = controlpy.synthesis.controller_lqr_discrete_time(A_np, B_np, Q_np, R_np)\n",
    "x_np = x0\n",
    "u_np = (-K@x_np)\n",
    "xs_np, us_np = np.array(x_np), np.array(u_np)\n",
    "loss_np = 0\n",
    "for i in range(T):\n",
    "    loss_np += x_np.T@Q_np@x_np + u_np.T*R_np*u_np\n",
    "    x_np = A_np@x_np + B_np@u_np\n",
    "    u_np = (-K@x_np)\n",
    "    xs_np = np.hstack([xs_np, x_np])\n",
    "    us_np = np.hstack([us_np, u_np])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.71948966]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling iter_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/nishant/ray_results/2018-08-26_22-43-29r4a9tt7u/iter_vars.pkl', 'rb') as file:\n",
    "    v = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
