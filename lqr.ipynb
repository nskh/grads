{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/flow/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/envs/flow/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from ray.experimental.tfutils import TensorFlowVariables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1600px;height:750px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1.001, 0], [0, 0.5]])\n",
    "B = np.array([[1.], [1.]])\n",
    "\n",
    "# for controllability\n",
    "cont = np.hstack([B, A@B, A@A@B])\n",
    "assert np.linalg.matrix_rank(cont)==cont.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([[1.], [1.]])  # 2x1 vector \n",
    "\n",
    "A = tf.constant(np.array([[1.001, 0], [0, -0.6]]), dtype=tf.float32, name='A')  # system dynamics\n",
    "B = tf.constant(np.array([[1.], [1.]]), dtype=tf.float32, name='B')\n",
    "\n",
    "Q = tf.constant([[1.,0.], [0.,1.]], name='Q')  # weighting\n",
    "R = tf.constant(1., name='R')\n",
    "\n",
    "x = tf.constant(x0, dtype=tf.float32, name=\"state\")\n",
    "\n",
    "T = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "####### Defining network #######\n",
    "# input: state x\n",
    "# output: control u\n",
    "\n",
    "input_layer = tf.placeholder(tf.float32, (None,2), name='in_layer')\n",
    "# fc1 = tf.layers.dense(inputs=input_layer, units=1, name='fc1', reuse=tf.AUTO_REUSE)\n",
    "# u = tf.layers.dense(inputs=fc1, units=1, name='fc_out', reuse=tf.AUTO_REUSE)\n",
    "u = tf.layers.dense(inputs=input_layer, units=1, name='u_out_layer', reuse=tf.AUTO_REUSE)\n",
    "\n",
    "### LOSS FUNCTION ### \n",
    "loss = tf.add(tf.matmul(tf.matmul(tf.transpose(x), Q), x), \n",
    "              tf.matmul(tf.transpose(u), tf.multiply(R, u)), name='loss')\n",
    "\n",
    "# xs = tf.identity(x, name='xs')\n",
    "# us = tf.constant(0, name='us')\n",
    "xs = x\n",
    "us = u\n",
    "\n",
    "# cond = lambda i, x, l, xs, us: i < T\n",
    "\n",
    "# def body(i, x, l, xs, us):\n",
    "#     next_i = i+1\n",
    "#     next_x = tf.add(tf.matmul(A, x), tf.multiply(u,B))\n",
    "#     next_l = tf.add(l,\n",
    "#                     tf.add(tf.matmul(tf.matmul(tf.transpose(x), Q), x),\n",
    "#                            tf.matmul(tf.transpose(u), tf.multiply(R, u))))\n",
    "#     next_xs = tf.concat(xs, next_x)\n",
    "#     next_us = tf.concat(us, u)\n",
    "#     return (next_i, next_x, next_l, next_xs, next_us)\n",
    "\n",
    "# i, xloss_f, traj_f = tf.while_loop(cond, body, \n",
    "#                                    loop_vars=[tf.constant(0), x, loss, xs, us],\n",
    "#                                    shape_invariants=[tf.TensorShape([1,]), tf.TensorShape([2, 1]), \n",
    "#                                                      tf.TensorShape([1,]) , tf.TensorShape([2, None]), \n",
    "#                                                      tf.TensorShape([1, None])])\n",
    "# train = tf.train.GradientDescentOptimizer(0.01).minimize(xloss_f.loss)\n",
    "\n",
    "for i in range(T):\n",
    "    # LQR loss \n",
    "#     x_term = tf.matmul(tf.matmul(tf.transpose(x), Q), x, name='x_term')\n",
    "#     u_term = tf.matmul(tf.transpose(u), tf.multiply(R, u), name='u_term')\n",
    "#     loss = tf.add(loss, tf.add(x_term, u_term), name='loss')  # accumulate loss\n",
    "    \n",
    "    # Dynamics: advancing the system dynamics\n",
    "    Ax = tf.matmul(A, x, name='Ax'+str(i))\n",
    "    Bu = tf.multiply(u, B, name='Bu'+str(i))  # tf.multiply because u is a scalar\n",
    "    x = tf.add(Ax, Bu, name='state'+str(i))  # next state vector\n",
    "\n",
    "    loss = tf.add(loss, tf.add(tf.matmul(tf.matmul(tf.transpose(x), Q), x), tf.matmul(tf.transpose(u), tf.multiply(R, u))), name='loss'+str(i))  # accumulate loss    \n",
    "    \n",
    "    u = tf.layers.dense(inputs=tf.transpose(x), units=1, name='u_out_layer', reuse=True)\n",
    "    \n",
    "#     fc1 = tf.layers.dense(inputs=tf.transpose(x), units=1, name='fc1', reuse=True)\n",
    "#     u = tf.layers.dense(inputs=fc1, units=1, name='fc_out', reuse=True)\n",
    "    \n",
    "    xs = tf.concat([xs, x], 1)\n",
    "    us = tf.concat([us, u], 1)\n",
    "    \n",
    "opt = tf.train.GradientDescentOptimizer(0.0001)\n",
    "train = opt.minimize(loss)\n",
    "grads_and_vars = opt.compute_gradients(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'u_out_layer/bias': array([0.01161656], dtype=float32),\n",
       " 'u_out_layer/kernel': array([[-1.086187  ],\n",
       "        [-0.03679204]], dtype=float32)}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_weights = v[-1]['weights'].copy()\n",
    "new_weights['u_out_layer/bias'] = new_weights.pop('fc1/biases')\n",
    "new_weights['u_out_layer/kernel'] = new_weights.pop('fc1/weights')\n",
    "del new_weights['fc_out/biases']\n",
    "del new_weights['fc_out/weights']\n",
    "new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'u_out_layer/bias': array([0.], dtype=float32),\n",
       " 'u_out_layer/kernel': array([[ 0.09326291],\n",
       "        [-0.65355664]], dtype=float32)}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradients\n",
      "[[-18.960514]\n",
      " [-47.901035]] - u_out_layer/kernel:0\n",
      "gradients\n",
      "[-11.397677] - u_out_layer/bias:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[-18.960514], [-47.901035]]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "variables = TensorFlowVariables(loss, sess)\n",
    "variables.set_weights(new_weights)\n",
    "for g, v in grads_and_vars:\n",
    "    print('gradients')\n",
    "    print(str(sess.run(g, feed_dict={input_layer : x0.T})) + \" - \" + v.name)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training iteration 0\n",
      "xs\n",
      "[[ 1.          1.6705077   1.4057143   0.8651598   0.38684186  0.08079776\n",
      "  -0.06432917 -0.10282908 -0.08857299 -0.05855154 -0.03181436]\n",
      " [ 1.          0.0695076  -0.30816853 -0.35705918 -0.26494765 -0.14746237\n",
      "  -0.05673031 -0.0043974   0.01699736  0.01991161  0.01484877]]\n",
      "\n",
      "us\n",
      "[[ 0.6695076  -0.26646397 -0.5419603  -0.47918317 -0.30643097 -0.14520773\n",
      "  -0.03843558  0.01435892  0.03011003  0.02679574  0.01721367]]\n",
      "\n",
      "loss\n",
      "[[9.630793]]\n",
      "\n",
      "gradients\n",
      "[[25.11649 ]\n",
      " [16.611288]] - u_out_layer/kernel:0\n",
      "[16.758821] - u_out_layer/bias:0\n",
      "----------------------\n",
      "training iteration 100\n",
      "xs\n",
      "[[ 1.          1.4136603   0.8282422   0.20646822 -0.12854722 -0.21178775\n",
      "  -0.17515226 -0.11803137 -0.08181047 -0.0696028  -0.07087626]\n",
      " [ 1.         -0.18733984 -0.4744279  -0.33794546 -0.13245463 -0.00363919\n",
      "   0.03903079  0.03387757  0.01601239  0.00268205 -0.00281309]]\n",
      "\n",
      "us\n",
      "[[ 0.41266018 -0.5868318  -0.6226022  -0.33522192 -0.08311197  0.03684728\n",
      "   0.05729605  0.03633894  0.01228949 -0.00120386 -0.004872  ]]\n",
      "\n",
      "loss\n",
      "[[6.4424615]]\n",
      "\n",
      "gradients\n",
      "[[ 5.869818]\n",
      " [10.263525]] - u_out_layer/kernel:0\n",
      "[-0.46807826] - u_out_layer/bias:0\n",
      "----------------------\n",
      "training iteration 200\n",
      "xs\n",
      "[[ 1.          1.2859058   0.6199979   0.07734537 -0.13473088 -0.14531164\n",
      "  -0.0984752  -0.06274734 -0.0495508  -0.04939447 -0.05266284]\n",
      " [ 1.         -0.31509417 -0.4781373  -0.25639015 -0.05831949  0.02454567\n",
      "   0.03225435  0.01647373  0.00337506 -0.00181915 -0.00212748]]\n",
      "\n",
      "us\n",
      "[[ 2.8490585e-01 -6.6719383e-01 -5.4327255e-01 -2.1215360e-01\n",
      "  -1.0446031e-02  4.6981748e-02  3.5826340e-02  1.3259295e-02\n",
      "   2.0588003e-04 -3.2189693e-03 -2.2915062e-03]]\n",
      "\n",
      "loss\n",
      "[[5.454905]]\n",
      "\n",
      "gradients\n",
      "[[3.4325721]\n",
      " [7.614882 ]] - u_out_layer/kernel:0\n",
      "[-0.4645012] - u_out_layer/bias:0\n",
      "----------------------\n",
      "training iteration 300\n",
      "xs\n",
      "[[ 1.0000000e+00  1.1938199e+00  4.9760336e-01  3.3973247e-02\n",
      "  -1.0539897e-01 -9.5098026e-02 -6.0223762e-02 -4.1106548e-02\n",
      "  -3.6625274e-02 -3.7820488e-02 -3.9467815e-02]\n",
      " [ 1.0000000e+00 -4.0718016e-01 -4.5310229e-01 -1.9226637e-01\n",
      "  -2.4046361e-02  2.4834160e-02  2.0068867e-02  7.1361195e-03\n",
      "   2.4070963e-04 -1.3030153e-03 -8.2769408e-04]]\n",
      "\n",
      "us\n",
      "[[ 0.19281986 -0.6974104  -0.46412775 -0.13940619  0.01040634  0.03496936\n",
      "   0.01917744  0.00452238 -0.00115859 -0.0016095  -0.00071812]]\n",
      "\n",
      "loss\n",
      "[[4.9107947]]\n",
      "\n",
      "gradients\n",
      "[[2.3521924]\n",
      " [6.035102 ]] - u_out_layer/kernel:0\n",
      "[-0.3609227] - u_out_layer/bias:0\n",
      "----------------------\n",
      "training iteration 400\n",
      "xs\n",
      "[[ 1.0000000e+00  1.1222370e+00  4.1785789e-01  2.1861166e-02\n",
      "  -7.5053029e-02 -6.2410418e-02 -3.9900552e-02 -2.9936660e-02\n",
      "  -2.8276492e-02 -2.9010218e-02 -2.9671963e-02]\n",
      " [ 1.0000000e+00 -4.7876310e-01 -4.1824344e-01 -1.4546853e-01\n",
      "  -9.6549317e-03  1.8510627e-02  1.1465902e-02  3.1242515e-03\n",
      "  -1.8444448e-04 -5.9477944e-04 -2.7586636e-04]]\n",
      "\n",
      "us\n",
      "[[ 1.21236905e-01 -7.05501318e-01 -3.96414608e-01 -9.69360545e-02\n",
      "   1.27176670e-02  2.25722790e-02  1.00037931e-02  1.69010647e-03\n",
      "  -7.05446117e-04 -6.32734038e-04 -2.04371288e-04]]\n",
      "\n",
      "loss\n",
      "[[4.569362]]\n",
      "\n",
      "gradients\n",
      "[[1.7209544]\n",
      " [4.9446573]] - u_out_layer/kernel:0\n",
      "[-0.29057032] - u_out_layer/bias:0\n",
      "----------------------\n",
      "training iteration 500\n",
      "xs\n",
      "[[ 1.0000000e+00  1.0646552e+00  3.6350286e-01  2.3169458e-02\n",
      "  -4.9484424e-02 -4.0909380e-02 -2.7668668e-02 -2.2479266e-02\n",
      "  -2.1693522e-02 -2.1976858e-02 -2.2210348e-02]\n",
      " [ 1.0000000e+00 -5.3634489e-01 -3.8041005e-01 -1.1245090e-01\n",
      "  -5.2065104e-03  1.1748438e-02  6.2325601e-03  1.4775363e-03\n",
      "  -7.8297744e-05 -2.1466246e-04 -8.2716113e-05]]\n",
      "\n",
      "us\n",
      "[[ 6.3655145e-02 -7.0221698e-01 -3.4069693e-01 -7.2677054e-02\n",
      "   8.6245313e-03  1.3281623e-02  5.2170726e-03  8.0822408e-04\n",
      "  -2.6164111e-04 -2.1151360e-04 -5.2610412e-05]]\n",
      "\n",
      "loss\n",
      "[[4.341079]]\n",
      "\n",
      "gradients\n",
      "[[1.2997652]\n",
      " [4.1290917]] - u_out_layer/kernel:0\n",
      "[-0.24145919] - u_out_layer/bias:0\n",
      "----------------------\n",
      "training iteration 600\n",
      "xs\n",
      "[[ 1.0000000e+00  1.0174576e+00  3.2559884e-01  3.0366272e-02\n",
      "  -2.9079292e-02 -2.6212871e-02 -1.9340508e-02 -1.6697137e-02\n",
      "  -1.6229380e-02 -1.6282408e-02 -1.6349416e-02]\n",
      " [ 1.0000000e+00 -5.8354247e-01 -3.4275073e-01 -8.9907736e-02\n",
      "  -5.5312887e-03  6.2142760e-03  3.1700130e-03  7.6070440e-04\n",
      "   2.8032722e-05 -5.3618052e-05 -1.8553652e-05]]\n",
      "\n",
      "us\n",
      "[[ 1.6457569e-02 -6.9287622e-01 -2.9555818e-01 -5.9475932e-02\n",
      "   2.8955028e-03  6.8985787e-03  2.6627122e-03  4.8445538e-04\n",
      "  -3.6798418e-05 -5.0724484e-05 -7.0366077e-06]]\n",
      "\n",
      "loss\n",
      "[[4.182876]]\n",
      "\n",
      "gradients\n",
      "[[0.9967633]\n",
      " [3.48765  ]] - u_out_layer/kernel:0\n",
      "[-0.20395258] - u_out_layer/bias:0\n",
      "----------------------\n",
      "training iteration 700\n",
      "xs\n",
      "[[ 1.0000000e+00  9.7834265e-01  2.9887474e-01  3.9893925e-02\n",
      "  -1.3056263e-02 -1.5696991e-02 -1.3099289e-02 -1.1923487e-02\n",
      "  -1.1649875e-02 -1.1625155e-02 -1.1634333e-02]\n",
      " [ 1.0000000e+00 -6.2265742e-01 -3.0685186e-01 -7.5168580e-02\n",
      "  -7.8889318e-03  2.1056894e-03  1.3499873e-03  3.7890882e-04\n",
      "   5.8191217e-05  1.4562102e-06  1.5742553e-06]]\n",
      "\n",
      "us\n",
      "[[-2.2657381e-02 -6.8044633e-01 -2.5927970e-01 -5.2990083e-02\n",
      "  -2.6276701e-03  2.6134010e-03  1.1889013e-03  2.8553652e-04\n",
      "   3.6370941e-05  2.4479814e-06  6.4317137e-06]]\n",
      "\n",
      "loss\n",
      "[[4.0708714]]\n",
      "\n",
      "gradients\n",
      "[[0.7684495]\n",
      " [2.966121 ]] - u_out_layer/kernel:0\n",
      "[-0.17313091] - u_out_layer/bias:0\n",
      "----------------------\n",
      "training iteration 800\n",
      "xs\n",
      "[[ 1.00000000e+00  9.45716441e-01  2.79973984e-01  4.99915928e-02\n",
      "  -4.96856868e-04 -7.82837532e-03 -8.12793709e-03 -7.90435355e-03\n",
      "  -7.81289116e-03 -7.79096875e-03 -7.78741017e-03]\n",
      " [ 1.00000000e+00 -6.55283630e-01 -2.73517996e-01 -6.61515743e-02\n",
      "  -1.08474977e-02 -8.22522212e-04  2.01780058e-04  1.10644316e-04\n",
      "   3.29806353e-05  9.94711809e-06  5.38198992e-06]]\n",
      "\n",
      "us\n",
      "[[-5.5283591e-02 -6.6668820e-01 -2.3026238e-01 -5.0538443e-02\n",
      "  -7.3310211e-03 -2.9173330e-04  2.3171236e-04  9.9367229e-05\n",
      "   2.9735500e-05  1.1350261e-05  8.0489554e-06]]\n",
      "\n",
      "loss\n",
      "[[3.9905543]]\n",
      "\n",
      "gradients\n",
      "[[0.5912658]\n",
      " [2.5325668]] - u_out_layer/kernel:0\n",
      "[-0.14657846] - u_out_layer/bias:0\n",
      "----------------------\n",
      "training iteration 900\n",
      "xs\n",
      "[[ 1.0000000e+00  9.1840601e-01  2.6664943e-01  5.9787512e-02\n",
      "   9.3942434e-03 -1.7092349e-03 -4.0383344e-03 -4.5138993e-03\n",
      "  -4.6094912e-03 -4.6285256e-03 -4.6322937e-03]\n",
      " [ 1.0000000e+00 -6.8259406e-01 -2.4311858e-01 -6.1257422e-02\n",
      "  -1.3698604e-02 -2.8937096e-03 -5.9116445e-04 -1.1682761e-04\n",
      "  -2.0981308e-05 -1.8360042e-06  1.9621448e-06]]\n",
      "\n",
      "us\n",
      "[[-8.25940073e-02 -6.52675033e-01 -2.07128584e-01 -5.04530594e-02\n",
      "  -1.11128725e-02 -2.32739025e-03 -4.71526291e-04 -9.10778763e-05\n",
      "  -1.44247897e-05  8.60542059e-07  3.88920307e-06]]\n",
      "\n",
      "loss\n",
      "[[3.9325335]]\n",
      "\n",
      "gradients\n",
      "[[0.4511701]\n",
      " [2.166825 ]] - u_out_layer/kernel:0\n",
      "[-0.12310909] - u_out_layer/bias:0\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(1000):\n",
    "#         sess.run(train)\n",
    "        sess.run(train, feed_dict={input_layer : x0.T})\n",
    "        if i % 100 == 0:\n",
    "#             results = sess.run([xs, us, loss, grads_and_vars], feed_dict={input_layer : x0.T})\n",
    "            results = sess.run([xs, us, loss], feed_dict={input_layer : x0.T})\n",
    "            labels  = \"xs us loss\".split(' ')\n",
    "            print('training iteration', i)\n",
    "            for label,result in zip(*(labels,results)) :\n",
    "                print(label)\n",
    "                print(result)\n",
    "                print('')\n",
    "            print('gradients')\n",
    "            for g, v in grads_and_vars:\n",
    "                print(str(sess.run(g, feed_dict={input_layer : x0.T})) + \" - \" + v.name)\n",
    "            print('----------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## compute optimal loss with true LQR ricatti equation formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import controlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    A_np, B_np, Q_np, R_np = sess.run([A, B, Q, R])\n",
    "\n",
    "K, P, eig = controlpy.synthesis.controller_lqr_discrete_time(A_np, B_np, Q_np, R_np)\n",
    "x_np = x0\n",
    "u_np = (-K@x_np)\n",
    "xs_np, us_np = np.array(x_np), np.array(u_np)\n",
    "loss_np = 0\n",
    "for i in range(T):\n",
    "    loss_np += x_np.T@Q_np@x_np + u_np.T*R_np*u_np\n",
    "    x_np = A_np@x_np + B_np@u_np\n",
    "    u_np = (-K@x_np)\n",
    "    xs_np = np.hstack([xs_np, x_np])\n",
    "    us_np = np.hstack([us_np, u_np])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.71948966]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling iter_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/nishant/ray_results/2018-08-26_22-43-29r4a9tt7u/iter_vars.pkl', 'rb') as file:\n",
    "    v = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fc1/biases': array([0.01161656], dtype=float32),\n",
       " 'fc1/weights': array([[-1.086187  ],\n",
       "        [-0.03679204]], dtype=float32),\n",
       " 'fc_out/biases': array([-0.03084663], dtype=float32),\n",
       " 'fc_out/weights': array([[0.38942182]], dtype=float32)}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[-1]['weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
